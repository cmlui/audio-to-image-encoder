{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pickle\n",
    "import lws\n",
    "import numpy as np\n",
    "import librosa\n",
    "import audio_model.preprocess as preprocess\n",
    "from audio_model.autoencoder import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matching parameters in preprocess.ipynb\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 1.48\n",
    "MONO = True\n",
    "FILE_PATH = \"random_audio/sugar.wav\"\n",
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the audio clip\n",
    "loader = preprocess.Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "signal = loader.load(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add padding\n",
    "num_expected_samples = int(SAMPLE_RATE * DURATION)\n",
    "if len(signal) < num_expected_samples:\n",
    "    num_missing_samples = num_expected_samples - len(signal)\n",
    "    signal = np.pad(signal, (0, num_missing_samples), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract log spectrogram\n",
    "log_spectrogram_extractor = preprocess.LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "log_spectrogram = log_spectrogram_extractor.extract(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the minmax value of dataset for normalizing the signal\n",
    "with open (\"audio_model/minmax/min_max_values.pkl\" , \"rb\")as f:\n",
    "     min_max = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the signal and reshape it\n",
    "MIN = 0\n",
    "MAX = 1\n",
    "normalized_array = (log_spectrogram - min_max['min']) / (min_max['max'] - min_max['min'])\n",
    "normalized_array = normalized_array * (MAX - MIN) + MIN\n",
    "normalized_array = normalized_array[..., np.newaxis]\n",
    "normalized_array = np.array([normalized_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the latent respresentation and reconstructed spectrogram\n",
    "vae = VAE.load(\"audio_model/model\")\n",
    "generated_spectrogram, audio_representation = vae.reconstruct(normalized_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the latent representation for the image model\n",
    "np.save('audio_representation',audio_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to reconstructed audio from the generated spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the spectrogram to signal\n",
    "#reshape the generated spectrogram to 3-d\n",
    "log_spectrogram = generated_spectrogram[0]\n",
    "\n",
    "# reshape the log spectrogram\n",
    "log_spectrogram = log_spectrogram[:,:, 0]\n",
    "\n",
    "# apply denormalisation\n",
    "denormalized_log_spectrogram = (log_spectrogram - MIN) / (MAX - MIN)\n",
    "denormalized_log_spectrogram = denormalized_log_spectrogram * (min_max[\"max\"] - min_max[\"min\"]) + min_max[\"min\"]\n",
    "\n",
    "# log spectrogram -> spectrogram\n",
    "spectrogram = librosa.db_to_amplitude(denormalized_log_spectrogram)\n",
    "\n",
    "# pad zero to conform frequency bin to 257 to fit lws input shape\n",
    "spectrogram_padded = np.pad(spectrogram,((0,1),(0,1)))\n",
    "\n",
    "# apply lws phase reconstruction\n",
    "lws_processor=lws.lws(512,256, mode=\"speech\") \n",
    "spectrogram_with_phase = lws_processor.run_lws(spectrogram_padded)\n",
    "\n",
    "# apply lws isft\n",
    "reconstructed_signal = lws_processor.istft(spectrogram_with_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(reconstructed_signal, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kennel before running this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.saved_model.load('image_model/generator_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_representation = np.load('audio_representation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(audio_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_image *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(generated_image[0].numpy().astype(np.uint8)).save('generated_image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "tenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
