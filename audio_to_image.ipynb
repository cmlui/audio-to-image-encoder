{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pickle\n",
    "import lws\n",
    "import numpy as np\n",
    "import librosa\n",
    "import audio_model.preprocess as preprocess\n",
    "from audio_model.autoencoder import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matching parameters in preprocess.ipynb\n",
    "sample_rate = 22050\n",
    "duration = 1.48\n",
    "mono = True\n",
    "file_path = \"random_audio/sugar.wav\"\n",
    "frame_size = 512\n",
    "hop_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the audio clip\n",
    "loader = preprocess.Loader(sample_rate, duration, mono)\n",
    "signal = loader.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add padding\n",
    "num_expected_samples = int(sample_rate * duration)\n",
    "if len(signal) < num_expected_samples:\n",
    "    num_missing_samples = num_expected_samples - len(signal)\n",
    "    signal = np.pad(signal, (0, num_missing_samples), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract log spectrogram\n",
    "log_spectrogram_extractor = preprocess.LogSpectrogramExtractor(frame_size, hop_length)\n",
    "log_spectrogram = log_spectrogram_extractor.extract(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the minmax value for normalizing the signal\n",
    "with open (\"audio_model/minmax/min_max_values.pkl\" , \"rb\")as f:\n",
    "     min_max = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the signal and reshape it\n",
    "norm_min = 0\n",
    "norm_max = 1\n",
    "norm_array = (log_spectrogram - min_max['min']) / (min_max['max'] - min_max['min'])\n",
    "norm_array = norm_array * (norm_max - norm_min) + norm_min\n",
    "norm_array_addaxis = norm_array[..., np.newaxis]\n",
    "norm_array_addaxis = np.array([norm_array_addaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the latent respresentation and reconstructed spectrogram\n",
    "vae = VAE.load(\"audio_model/model\")\n",
    "generated_spectrograms, audio_representations = vae.reconstruct(norm_array_addaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the latent representation for the image model\n",
    "np.save('audio_representations',audio_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to reconstructed audio from the generated spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the generated spectrogram to 3-d\n",
    "log_spectrogram = generated_spectrograms[0]\n",
    "\n",
    "# reshape the log spectrogram\n",
    "log_spectrogram = log_spectrogram[:,:, 0]\n",
    "\n",
    "# apply denormalisation\n",
    "denorm_log_spec = (log_spectrogram - norm_min) / (norm_max - norm_min)\n",
    "denorm_log_spec = denorm_log_spec * (min_max[\"max\"] - min_max[\"min\"]) + min_max[\"min\"]\n",
    "\n",
    "# log spectrogram -> spectrogram\n",
    "spec = librosa.db_to_amplitude(denorm_log_spec)\n",
    "\n",
    "# pad zero to conform frequency bin to 257 to fit lws input shape\n",
    "spec_pad = np.pad(spec,((0,1),(0,1)))\n",
    "\n",
    "# apply lws phase reconstruction\n",
    "lws_processor=lws.lws(512,256, mode=\"speech\") \n",
    "spec_phase = lws_processor.run_lws(spec_pad)\n",
    "\n",
    "# apply lws isft\n",
    "reconstruct_signal = lws_processor.istft(spec_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(reconstruct_signal, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kennel before running this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.saved_model.load('image_model/gen_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_representations = np.load('audio_representations.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(audio_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_image *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(generated_image[0].numpy().astype(np.uint8)).save('generated_image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "tenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
